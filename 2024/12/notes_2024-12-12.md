[Home](../../main.md) | [Prev: Day 46](notes_2024-12-11.md) | [Next: Day 48](./notes_2024-12-13.md)

## ðŸ“ Day 47, Thursday - `notes_2024-12-12.md`

- investigate 176 again  
- worked on 162 (MSR/OMSR for hibit 24 hr data) & 160 (TF-1 and SET2 agg data)
- 1on1 meeting
    * justin kuriani is running smarca2 hibit cell viability assay today so will have experiment affiliated with PRT# from project code 274; related to US176
    * Genaro said to expense chatgpt subscription and if rch won't do it, bill it to Genaro
    * need to re-think the ELN comparison (167) use of beautiful soup4 to scrape html and render into jupyter notebook
    * the full XPATH of writeup in ELN CHEM NEW is: `/html/body/div[5]/form/table/tbody/tr/td/table/tbody/tr[2]/td[2]/div[38]/table/tbody/tr/td/span/p[1]`
    * the run query button XPATH: `/html/body/main/div/section[1]/div/a[2]`
    * the LNB (exp id) input box XPATH: `/html/body/main/div/section[2]/div/div/div[2]/div/div[1]/form/table/tbody/tr/td/table/tbody/tr[2]/td[2]/div[7]/table/tbody/tr[1]/td/table/tbody/tr/td[2]/input[2]`
    * the url: `https://prelude-dev.dotmatics.net/browser/query/query.jsp?currentMode=query&currentProjectID=83000`
    * check proliferation data in JAK2-Degrader project (Assay Data Summary page) - showing up CTG in HIBIT table
    * the project ids for the placeholder masks issue are: 501, 521, 481, 522, 261, 81
- sql to get exp ids from affected CRO protocols for US167:

| ID  | Name                    | Description               |
|-----|-------------------------|---------------------------|
| 501 | CRO_Affinity_Wilmington | CRO ChemELN               |
| 481 | CRO_Affinity_Wuhan      | CRO ChemELN               |
| 521 | CRO_Affinity_Wuhan      | CRO ChemELN (not exist, or no placeholders present)   |
| 522 | CRO_Medicilon_Shanghai  | CRO ChemELN (not exist, or no placeholders present)   |
| 261 | CRO_Viva_ChemELN        | CRO ChemELN               |
| 81  | ChemELN                 | Dotmatics Chemistry ELN   |

```sql
WITH main AS (
SELECT 
experiment_id
FROM eln_writeup w WHERE EXISTS ( SELECT 1 FROM tm_protocols p JOIN tm_experiments e ON p.protocol_id = e.protocol_id WHERE e.experiment_id = w.experiment_id AND p.protocol_id IN (501, 521, 481, 522, 261, 81) ) AND INSTR(write_up, '{{') > 0
),
chunked_data AS (
    SELECT 
        CEIL(ROWNUM / 200) AS chunk_id,
        experiment_id
    FROM (SELECT experiment_id FROM main)
),
aggregated_chunks AS (
    SELECT 
        chunk_id,
        LISTAGG(experiment_id, ',') WITHIN GROUP (ORDER BY experiment_id) AS chunked_ids
    FROM chunked_data
    GROUP BY chunk_id
)
SELECT chunked_ids FROM aggregated_chunks
    

-- now with filter dates and combined randomized exp ids amounting to 100:

WITH main AS (
  SELECT *
    FROM tmp_affected_eln_writeup  
    WHERE protocol_id = 481
),
selected_pre_date AS (
    SELECT experiment_id
    FROM main
    WHERE ENTRY_DATE < TO_DATE('13-AUG-2024', 'DD-MON-YYYY')
    ORDER BY DBMS_RANDOM.VALUE
    FETCH FIRST 50 ROWS ONLY
),
selected_post_date AS (
    SELECT experiment_id
    FROM main
    WHERE ENTRY_DATE >= TO_DATE('13-AUG-2024', 'DD-MON-YYYY')
    ORDER BY DBMS_RANDOM.VALUE
    FETCH FIRST 50 ROWS ONLY
),
combined_selected AS (
    SELECT experiment_id FROM selected_pre_date
    UNION ALL
    SELECT experiment_id FROM selected_post_date
),
chunked_data AS (
    SELECT 
        CEIL(ROWNUM / 100) AS chunk_id,
        experiment_id
    FROM (SELECT experiment_id FROM combined_selected)
),
aggregated_chunks AS (
    SELECT 
        chunk_id,
        LISTAGG(experiment_id, ',') WITHIN GROUP (ORDER BY experiment_id) AS chunked_ids
    FROM chunked_data
    GROUP BY chunk_id
)
SELECT chunked_ids 
FROM aggregated_chunks
;

-- look for protocols
SELECT
       t3.protocol_id,
       t3.protocol,
       t3.descr
     FROM ds3_userdata.tm_protocols t3
--where protocol_id
--IN (501, 521, 481, 522, 261, 81)
order by protocol

--created tmp table to do lookup faster
SELECT 
     *
FROM TMP_AFFECTED_ELN_WRITEUP
where protocol_id = 481
```

- worked on 167 to create selenium python script to mimic navigating the DM platform
