[Home](../../main.md) | [Prev: Day 88](notes_2025-02-18.md) | [Next: Day 90](./notes_2025-02-20.md)

## 📝 Day 89, Wednesday - `notes_2025-02-19.md`

- US214:
    * completed entire run for 87k records
    * no errors
    * download missing exp ids
    * sql to calc stats

```sql
WITH filtered_experiments AS (
    SELECT DISTINCT e.exp_id, 
        (e.summary_data::jsonb ->> 'PROTOCOL_ID')::integer AS protocol_id
    FROM ELN_WRITEUP_API_EXTRACT e
    WHERE (e.summary_data::jsonb ->> 'PROTOCOL_ID')::integer IN (501, 481)
),
comparison_data AS (
    SELECT c.exp_id, 
        c.analysis_date,
        c.match_percentage,
        c.scibert_score,
        c.tfidf_score
    FROM ELN_WRITEUP_COMPARISON c
    INNER JOIN filtered_experiments fe ON c.exp_id = fe.exp_id
),
stats_before AS (
    SELECT 
        'match_percentage' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.match_percentage AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'

    UNION ALL

    SELECT 
        'tfidf_score' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.tfidf_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'

    UNION ALL

    SELECT 
        'scibert_score' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.scibert_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'
),
stats_after AS (
    SELECT 
        'match_percentage' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.match_percentage AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date IN ('2025-02-18', '2025-02-19')

    UNION ALL

    SELECT 
        'tfidf_score' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.tfidf_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date IN ('2025-02-18', '2025-02-19')

    UNION ALL

    SELECT 
        'scibert_score' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.scibert_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date IN ('2025-02-18', '2025-02-19')
)
SELECT 
    metric,
    analysis,
    COUNT(value) AS count,
    MIN(value) AS min,
    MAX(value) AS max,
    AVG(value) AS average,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY value) AS median,
    STDDEV(value) AS stdev
FROM (
select * from stats_before
UNION ALL
select * from stats_after
)
GROUP BY metric, analysis
ORDER BY metric, analysis desc
;

-- show constraints
SELECT constraint_name, table_name, column_name, ordinal_position FROM information_schema.key_column_usage WHERE table_name = 'eln_writeup_comparison';
;


-- testing locally on psql for the scrapped version
delete from eln_writeup_scrapped where system_name like 'prelude-mask%';

ALTER TABLE eln_writeup_comparison
DROP CONSTRAINT eln_writeup_comparison_exp_id_system_name_1_analysis_date_fkey;
```

- 1on1 Genaro:
    * now want to compare 18-feb vs 05-feb to convince that the data is the same? possibility based on de-duplication of data
    * 27 feb seems like a morning for testing of the newly fresh prod clone
    * the data looks worse (lower) because of the placeholders
    * Since the API includes place holders {{uid: X, id: Y }} the match percentage and tfidf scores are lower after the bug fix since the uid and ids are completely different; we need to use web-scrapping to do a text-to-text comparison as was analysed in spotfire visuals
    * re-wrote `compr_eln_writeup_scrape.py` to accommodate for the changes and requests

- US216:
    * the logic is:
      *  login into DMX platform search by exp id scrape tables and textboxes, save to psql db, sleep timer for 100 ms, query both writeups from psql db table, run ml calculations and save to psql db table, eln_writeup_comparison
      * significantly changes logic and codebase. The use of conda environments has been implemented previously, and two environments were created for modularization of code and environments 1) api 2) scrape. however now the scrape requires the python torch libraries which only existed in api. Requires download of torch libraries and dependencies (~2+ GB). Also had to modularize the code in order to re-use the ml functions, since they were the exact same functions and no reason to duplicate again in a separate python script.
      * added logging for traceability 


