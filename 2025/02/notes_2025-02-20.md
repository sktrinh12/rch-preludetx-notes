[Home](../../main.md) | [Prev: Day 89](notes_2025-02-19.md) | [Next: Day 91](./notes_2025-02-21.md)

## ðŸ“ Day 90, Thursday - `notes_2025-02-20.md`

- 1on1 Genaro US216:
    * the scrape is an html so need to remove html tags and feed into calculations
    * use of context manager for database connection
    * updated dev ops board with links to commit history
    * alter table sql:

```sql
-- on prelude discoix server
ALTER TABLE eln_writeup_comparison
DROP CONSTRAINT eln_writeup_comparison_exp_id_system_name_1_fkey;

-- misc queries on server for testing:
SELECT * from ELN_WRITEUP_COMPARISON WHERE analysis_date >= CURRENT_DATE - INTERVAL '2 days';

SELECT
    AVG(match_percentage) AS avg_match_percentage,
    AVG(tfidf_score) AS avg_tfidf_score
FROM
    ELN_WRITEUP_COMPARISON
WHERE
    analysis_date >= CURRENT_DATE - INTERVAL '2 days';

select * from eln_writeup_comparison where analysis_date >= CURRENT_DATE - INTERVAL '2 days';

select distinct exp_id from eln_writeup_comparison where analysis_date = '2025-02-05';

-- calcs for metrics

WITH filtered_experiments AS (
    SELECT DISTINCT e.exp_id, 
        (e.summary_data::jsonb ->> 'PROTOCOL_ID')::integer AS protocol_id
    FROM ELN_WRITEUP_API_EXTRACT e
    WHERE (e.summary_data::jsonb ->> 'PROTOCOL_ID')::integer IN (501, 481)
),
comparison_data AS (
    SELECT c.exp_id, 
        c.analysis_date,
        c.match_percentage,
        c.scibert_score,
        c.tfidf_score
    FROM ELN_WRITEUP_COMPARISON c
    INNER JOIN filtered_experiments fe ON c.exp_id = fe.exp_id
),
stats_before AS (
    SELECT 
        'match_percentage' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.match_percentage AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'

    UNION ALL

    SELECT 
        'tfidf_score' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.tfidf_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'

    UNION ALL

    SELECT 
        'scibert_score' AS metric,
        'before' as analysis,
        c1.analysis_date,
        c1.scibert_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-01-30'
),
stats_after AS (
    SELECT 
        'match_percentage' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.match_percentage AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-02-20'

    UNION ALL

    SELECT 
        'tfidf_score' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.tfidf_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-02-20'

    UNION ALL

    SELECT 
        'scibert_score' AS metric,
        'after' as analysis,
        c1.analysis_date,
        c1.scibert_score AS value
    FROM comparison_data c1
    JOIN filtered_experiments fe 
        ON c1.exp_id = fe.exp_id
    WHERE c1.analysis_date = '2025-02-20'
)
SELECT 
    metric,
    analysis,
    COUNT(value) AS count,
    MIN(value) AS min,
    MAX(value) AS max,
    AVG(value) AS average,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY value) AS median,
    STDDEV(value) AS stdev
FROM (
select * from stats_before
UNION ALL
select * from stats_after
)
GROUP BY metric, analysis
ORDER BY metric, analysis desc
;


-- quick avg calc to check progress of text comparison calcs
select count(exp_id), ROUND(AVG(match_percentage), 4), ROUND(AVG(tfidf_score), 4), ROUND(AVG(scibert_score), 4) 
from eln_writeup_comparison where system_name_1 = 'prelude-masks2' 
and analysis_date = '2025-02-20'
;
```


- DevOps board discussion thread:
```sh
* branch            HEAD       -> FETCH_HEAD  
  Merge made by the 'ort' strategy.  

  File Name                                      | Changes  
  ---------------------------------------------- | ----------------------  
  compare_eln_writeup_dm_api.py                  |   57 modifications (-)  
  compr_eln_writeup_scrape.py                    |  318 modifications (-)  
  dm_scrape_requirements.txt                     |    4 additions (+)  
  fetch_compare_diff.py                          |  138 additions (+)  
  ml_modules.py                                  |   55 additions (+)  
  ---------------------------------------------- | ----------------------  
  **Total changes**: 426 insertions (+), 146 deletions (-)  
```

This shows the amount of changes I did for this request. Total lines of code for the main script is 479. All git logs reflect the changes made to successfully get this script to work. I ran into a few errors along the way like:

```
ERROR - Error during scraping: Message: 'chromedriver.exe' executable may have wrong permissions.

ERROR - Database connection error: insert or update on table "eln_writeup_comparison" violates foreign key constraint "eln_writeup_comparison_exp_id_system_name_1_fkey"
DETAIL:  Key (exp_id, system_name_1, analysis_date)=(192685, prelude-masks2, 2025-02-20) is not present in table "eln_writeup_api_extract".
```

- explanation
    * No write_up found for exp_id {exp_id} in system {system_name}.
    * The first error is because the way windows sets file permissions on the chromedriver.exe file. 
    * The second error is due to the foreign key constraint on comparison table. It is virtually impossible to foresee every future change and change request, I wouldn't have imagined we would run the script in such a manner, recall the scrapped data is in a separate table so these two projects [1) web scrape writeup 2) api call writeup] were initially isolated and did not relate to one another (thus the two conda environments), but now we are combining logic from both, so the only solution I could think of was to release the constraints from the database table
    * The third error involves race conditions between the psql query for the writeup thread and the comparison metric calculation psql thread; after investigation my solution pointed to using the threadpoolexecutor class to ensure the insert queries completed first prior to trying to execute the comparison calculations
    * Note** the scrape is an html output, so had to create a helper function to remove the html tags in order to feed into text comparison calculations

- unix command to check for errors in log file:
    * use WSL and change directory to `/mnt/c/Users/Disco-lx/`
    * error pointed to 192685 duplicate key, seemed to have already existed from prior run perhaps
    * appox calc of time to complete script: 3374 records / 200 records per hour = 16 hours
```bash
grep -i -C 2 'error' writeup_scrape_2025-02-20.log
```
