[Home](../../main.md) | [Prev: Day 127](notes_2025-04-16.md) | [Next: Day 129](./notes_2025-04-18.md)

## ðŸ“ Day 128, Thursday - `notes_2025-04-17.md`

- US261 - Create new modular `SUMM_JAK2` and test for equivalency
    * updated devops board with all sql and python code for this test
    * created all DS on DEV environment; now both environments have the `TMP_SUMM_JAK2` DS
    * tediously and carefully copy paste from table browser (DEV) results into `.csv` file; only can copy ~30-40 rows at a time and only max of 100 rows for each query
    * `TMP_OUTPUT_JAK2_PRTN` was compiled on PROD, but didn't exist even after successful compilation on DEV *unknown reason*
    * started working on jlab notebook to analyze `.csv` file

- BG260 - JAK2 studies not populating
    * perhaps DS not refreshed yesterday at the time they expected it since DSUPDATER was not running; only runs at 01:00 EST and if `Calculations` mode triggers Datasources?  
    * may need to look into a trigger that will happen on Weds around 13-14:00 EST for the JAK2 team
    * 269404, 269405 and 269406
    * wrote sql to grab PRT#s and data for these exp ids


```sql
-- view general data
WITH t AS
    (SELECT
       t4.experiment_id AS experiment_id,
       t3.display_name AS id,
       t6.name AS analysis_name,
       t10.plate_number,
       t1.status,
       t50.name AS status_name,
       t3.id AS sam_id,
       t4.protocol_id,
       t5.label AS classification,
       t11.well_analysis_id,
       t9.name AS name
     FROM ds3_userdata.su_analysis_results t1
     LEFT JOIN ds3_userdata.su_groupings t2 ON t1.group_id = t2.id
     LEFT JOIN ds3_userdata.su_samples t3 ON t2.sample_id = t3.id
     LEFT JOIN ds3_userdata.tm_experiments t4 ON t2.experiment_id = t4.experiment_id
     LEFT JOIN ds3_userdata.su_plates t10 ON t10.experiment_id = t2.experiment_id
     AND t2.plate_set = t10.plate_set
     LEFT JOIN
       (SELECT
          b.experiment_id,
          b.plate_number,
          a.plate_id,
          c.well_analysis_id,
          round(z_prime, 4) AS z_prime,
          low_avg,
          high_avg
        FROM ds3_userdata.su_plate_results a
        LEFT JOIN ds3_userdata.su_plates b ON a.plate_id = b.id
        LEFT JOIN ds3_userdata.su_well_layers c ON b.experiment_id = c.experiment_id
        AND a.layer_id = c.id
        WHERE c.well_analysis_id = 1
        ORDER BY
          b.experiment_id,
          b.plate_number) t11 ON t10.id = t11.plate_id
     LEFT JOIN ds3_userdata.su_classification_rules t5 ON t1.rule_id = t5.id
     LEFT JOIN ds3_userdata.su_analysis_layers t6 ON t1.layer_id = t6.id
     LEFT JOIN ds3_userdata.su_charts t7 ON t7.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_results t8 ON t8.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_analyses t9 ON t9.id = t8.derived_analysis_id
     LEFT JOIN ds3_userdata.su_statuses t50 ON t50.status = t1.status
     WHERE 
       T4.completed_date IS NOT NULL
       AND t4.protocol_id IN (
                                542,
                                543,
                                544,
                                561,
                                562))

     --AND T1.STATUS = 1
  SELECT *
  FROM t
  WHERE experiment_id IN (
                            269404, 269405, 269406
)
  ORDER BY experiment_id

-- count # of rows for each exp id 
WITH t AS (
    SELECT
       t4.experiment_id AS experiment_id,
       t3.display_name AS id,
       t6.name AS analysis_name,
       t10.plate_number,
       t1.status,
       t50.name AS status_name,
       t3.id AS sam_id,
       t4.protocol_id,
       t5.label AS classification,
       t11.well_analysis_id,
       t9.name AS name
     FROM ds3_userdata.su_analysis_results t1
     LEFT JOIN ds3_userdata.su_groupings t2 ON t1.group_id = t2.id
     LEFT JOIN ds3_userdata.su_samples t3 ON t2.sample_id = t3.id
     LEFT JOIN ds3_userdata.tm_experiments t4 ON t2.experiment_id = t4.experiment_id
     LEFT JOIN ds3_userdata.su_plates t10 ON t10.experiment_id = t2.experiment_id
       AND t2.plate_set = t10.plate_set
     LEFT JOIN (
        SELECT
          b.experiment_id,
          b.plate_number,
          a.plate_id,
          c.well_analysis_id,
          round(z_prime, 4) AS z_prime,
          low_avg,
          high_avg
        FROM ds3_userdata.su_plate_results a
        LEFT JOIN ds3_userdata.su_plates b ON a.plate_id = b.id
        LEFT JOIN ds3_userdata.su_well_layers c ON b.experiment_id = c.experiment_id
           AND a.layer_id = c.id
        WHERE c.well_analysis_id = 1
     ) t11 ON t10.id = t11.plate_id
     LEFT JOIN ds3_userdata.su_classification_rules t5 ON t1.rule_id = t5.id
     LEFT JOIN ds3_userdata.su_analysis_layers t6 ON t1.layer_id = t6.id
     LEFT JOIN ds3_userdata.su_charts t7 ON t7.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_results t8 ON t8.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_analyses t9 ON t9.id = t8.derived_analysis_id
     LEFT JOIN ds3_userdata.su_statuses t50 ON t50.status = t1.status
     WHERE 
       T4.completed_date IS NOT NULL
       AND t4.protocol_id IN (542, 543, 544, 561, 562)
)
SELECT experiment_id, COUNT(*) AS row_count
FROM t
WHERE experiment_id IN (269404, 269405, 269406)
GROUP BY experiment_id
ORDER BY experiment_id;


-- show unique formatted id and exp id in groups
WITH t AS
    (SELECT
       t4.experiment_id AS experiment_id,
       t3.display_name AS id,
       t6.name AS analysis_name,
       t10.plate_number,
       t1.status,
       t50.name AS status_name,
       t3.id AS sam_id,
       t4.protocol_id,
       t5.label AS classification,
       t11.well_analysis_id,
       t9.name AS name
     FROM ds3_userdata.su_analysis_results t1
     LEFT JOIN ds3_userdata.su_groupings t2 ON t1.group_id = t2.id
     LEFT JOIN ds3_userdata.su_samples t3 ON t2.sample_id = t3.id
     LEFT JOIN ds3_userdata.tm_experiments t4 ON t2.experiment_id = t4.experiment_id
     LEFT JOIN ds3_userdata.su_plates t10 ON t10.experiment_id = t2.experiment_id
     AND t2.plate_set = t10.plate_set
     LEFT JOIN
       (SELECT
          b.experiment_id,
          b.plate_number,
          a.plate_id,
          c.well_analysis_id,
          round(z_prime, 4) AS z_prime,
          low_avg,
          high_avg
        FROM ds3_userdata.su_plate_results a
        LEFT JOIN ds3_userdata.su_plates b ON a.plate_id = b.id
        LEFT JOIN ds3_userdata.su_well_layers c ON b.experiment_id = c.experiment_id
        AND a.layer_id = c.id
        WHERE c.well_analysis_id = 1
        ORDER BY
          b.experiment_id,
          b.plate_number) t11 ON t10.id = t11.plate_id
     LEFT JOIN ds3_userdata.su_classification_rules t5 ON t1.rule_id = t5.id
     LEFT JOIN ds3_userdata.su_analysis_layers t6 ON t1.layer_id = t6.id
     LEFT JOIN ds3_userdata.su_charts t7 ON t7.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_results t8 ON t8.result_id = t1.id
     LEFT JOIN ds3_userdata.su_derived_analyses t9 ON t9.id = t8.derived_analysis_id
     LEFT JOIN ds3_userdata.su_statuses t50 ON t50.status = t1.status
     WHERE 
       T4.completed_date IS NOT NULL
       AND t4.protocol_id IN (
                                542,
                                543,
                                544,
                                561,
                                562)),

     --AND T1.STATUS = 1
x as (  SELECT ID, experiment_id
  FROM t
  WHERE experiment_id IN (
                            269404, 269405, 269406
)
  --ORDER BY experiment_id
)
select unique substr(id, 1, 10) as formatted_id, experiment_id from x
ORDER by EXPERIMENT_ID
```

- US240 - DS refresh
- The `-DAYS-` flag works, but the `-TIMES-` flag won't work in this case because according to docs:

>When forcing a SQL runner via force/trigger (seeÂ [Schedule for SQL runner](https://documentation.dotmatics.com/br/6.2/admin-guide/settings/schedules/sql-runner-scheduling#id-.SQLRunnerv2020.1-Sch_sql_run)Â below) and DAYS and TIMES parameters are set, the SQL will only run if the DAYS and TIMES parameters match. If they do not match, the SQL will be skipped and a message will be displayed in the logs.

- Since the time that `GENERIC_ASSAY_DATA` DS is requested to be updated is on a Friday at 13:00, this doesn't not coincide with the 01:00 Datasource refresh schedule; and won't happen, the `-DAYS-` flag will work and will trigger immediately after the Datasource refresh
- Only way to trigger a specific project DS would be to build something external; also cannot use API since there is not exposed endpoints for `POST` or updating the schedules module, only to `GET` retrieve data:

>/schedules [admin]  
The schedules collection returns information about the schedules that run inside Browser and their  
configuration.
