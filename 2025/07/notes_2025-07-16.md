[Home](../../main.md) | [Prev: Day 189](notes_2025-07-15.md) | [Next: Day 191](./notes_2025-07-17.md)

## 📝 Day 190, Wednesday - `notes_2025-07-16.md`

### US332
- Investigate best methods for migrating Generic Assay results to TetraScience
    * read documentation and wrote notes from apache airflow official website
    * idea is to use docker compose to create a containerised version of airflow on the preludex01 server


### US333
- Update Geomean for KAT6B HIBIT
    * used this generic sql template to check changes made to summ_kat6a ds

```sql
-- check summ_kat6a after changes made
select 
ic50_nm_t47d,
abs_ic50_nm_t47d 
from summ_kat6a
where x01_formatted_id = 'PRT1004430'
union all
select null, null from dual
;


-- the above should match this:
SELECT *
  FROM (
          (SELECT
             formatted_id,
             power(10, avg(log(10, CASE
                                       WHEN ic50 > 0 THEN ic50
                                       ELSE NULL
                                   END))) AS p,
             NULL AS r,
             power(10, avg(log(10, CASE
                                       WHEN span > 0 THEN span
                                       ELSE NULL
                                   END))) AS pspan,
             power(10, avg(log(10, CASE
                                       WHEN MIN > 0 THEN MIN
                                       ELSE NULL
                                   END))) AS MIN,
             power(10, avg(log(10, CASE
                                       WHEN response_at_hc > 0 THEN response_at_hc
                                       ELSE NULL
                                   END))) AS presp_hc,
             NULL AS minr,
             stddev(ic50) AS sd,
             stddev(span) AS sdspan,
             power(10, avg(log(10, CASE
                                       WHEN absolute_ic50 > 0 THEN absolute_ic50
                                       ELSE NULL
                                   END))) AS abs_ic50,
             stddev(absolute_ic50) AS sd_abs_ic50,
             assay_type,
             cell_line,
             cells_well,
             compound_status,
             count(formatted_id) AS c,
             time_hr
           FROM ds3_userdata.kat6a_registry_summary
           WHERE compound_status IS NULL
           GROUP BY
             formatted_id,
             assay_type,
             cell_line,
             cells_well,
             time_hr,
             compound_status)
        UNION ALL
          (SELECT
             formatted_id,
             NULL AS p,
             max(ic50) AS r,
             power(10, avg(log(10, CASE
                                       WHEN span > 0 THEN span
                                       ELSE NULL
                                   END))) AS pspan,
             NULL AS MIN,
             power(10, avg(log(10, CASE
                                       WHEN response_at_hc > 0 THEN response_at_hc
                                       ELSE NULL
                                   END))) AS presp_hc,
             power(10, avg(log(10, CASE
                                       WHEN MIN > 0 THEN MIN
                                       ELSE NULL
                                   END))) AS minr,
             stddev(ic50) AS sd,
             stddev(span) AS sdspan,
             max(absolute_ic50) AS abs_ic50,
             stddev(absolute_ic50) AS sd_abs_ic50,
             assay_type,
             cell_line,
             cells_well,
             compound_status,
             count(formatted_id) AS c,
             time_hr
           FROM ds3_userdata.kat6a_registry_summary
           WHERE compound_status IS NOT NULL
           GROUP BY
             formatted_id,
             assay_type,
             cell_line,
             cells_well,
             time_hr,
             compound_status))
  WHERE formatted_id = 'PRT1004430'
    AND time_hr = 240
and cell_line = 'T47D'
;

-- try sql that will show prt#'s that have compound_status null & non-null

WITH matching_ids AS (
  SELECT formatted_id
  FROM ds3_userdata.kat6a_registry_summary

  GROUP BY formatted_id
  HAVING
    SUM(CASE WHEN compound_status IS NULL OR LENGTH(TRIM(compound_status)) = 0 THEN 1 ELSE 0 END) > 0
    AND
    SUM(CASE WHEN LENGTH(TRIM(compound_status)) > 0 THEN 1 ELSE 0 END) > 0
)
SELECT
    k.formatted_id,
    k.ic50,
    k.assay_type,
    k.cell_line,
    k.cells_well,
    k.time_hr,
    k.compound_status,
    k.classification,
    k.highest_conc,
    k.lowest_conc,
    ROW_NUMBER() OVER (
        PARTITION BY k.formatted_id, k.assay_type, k.cell_line, k.cells_well, k.time_hr, k.compound_status
        ORDER BY k.formatted_id
    ) AS rn
FROM ds3_userdata.kat6a_registry_summary k
JOIN matching_ids m
  ON k.formatted_id = m.formatted_id

ORDER BY
  k.formatted_id,
  rn DESC
```

### US106
- Dotmatics MW_EXACT in MW_VW
    * Genaro vocally approved during meeting to push to PROD
    * changed `REG_DATA_VW` and `MW_VW`

```sql
select * from reg_data_vw
where formatted_id = 'PRT1009876'
;

-- MW_VW
SELECT 
DISTINCT 
FORMATTED_ID,
MW_EXACT
FROM REG_DATA_VW
```

### US321
- Investigate method to monitor Dotmatics system performance
    * on SQL Runner; created a trigger that randomly inserts one row following the pre-defined schedule: `01:00, 12:00, 14:00, 15:00, 16:00, 16:42`
    * the trigger inserts into `MOCK_DATA` table (Datasource)
    * the python script executes 3 sql (shown below) queries in *table browser*
    * 3 sql queries:
        * (1) shows `MOCK_DATA` table size in MB
        * (2) shows tablespace size for all tablespaces on oracle database
        * (3) shows number of rows for `MOCK_DATA` table
    * the python script parses the output of *table browser* and uploads the data to InfluxDB on docker container
    * Grafana is running on docker container and is connected to InfluxDB
    * Grafana has a oracle-metrics dashboard that shows the time-series data from these 3 sql queries over time
    * only the (3) sql query shows a difference in data over time, since it is counting the row count; whereas others are not changing much over a small period of time


```sql
-- (1)
SELECT 
    segment_name AS name,
    ROUND(SUM(bytes) / (1024 * 1024), 2) AS size_mb
FROM 
    user_segments
WHERE 
    segment_type = 'TABLE'
    AND segment_name = 'MOCK_DATA'
GROUP BY 
    segment_name, segment_type
;

-- (2)
SELECT 
    a.tablespace_name AS name,
    ROUND((a.used_space * b.block_size) / POWER(1024, 3), 2) AS used_gib,
    ROUND((a.tablespace_size * b.block_size) / POWER(1024, 3), 2) AS total_gib,
    ROUND((a.used_space / a.tablespace_size) * 100, 2) AS pct_used
FROM 
    dba_tablespace_usage_metrics a
JOIN 
    dba_tablespaces b
ON 
    a.tablespace_name = b.tablespace_name
ORDER BY 
    pct_used DESC
;

-- (3)
SELECT 
    'MOCK_DATA' AS NAME,
    count(*) AS num_rows
FROM 
   MOCK_DATA 
;
```
