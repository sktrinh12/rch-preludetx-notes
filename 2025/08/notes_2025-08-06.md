[Home](../../main.md) | [Prev: Day 204](notes_2025-08-05.md) | [Next: Day 206](./notes_2025-08-07.md)

## üìù Day 205, Wednesday - `notes_2025-08-06.md`

### US341
- develop script to ingest tecan file and upload using mosaic api
    * continued work on `main.py` in `ssp-tecan-to-mosaci` self service pipeline
        * added new logic to update labware item sampleholders if labware item id (barcode) exists
        * added new logic to change display exponent for solvent volume
        * successfully ran Post tecan ids to mosaic samplebank pipeline on TS UAT
    * additional limitations identified in the AWS Athena IDS schema on Tetrascience:

#### x,y position flip-flop
	
**Issue:**
JSON payload showing incorrect positions for well locations

**Resolution:**
> The X-coordinate (column) of the sample holder within the labware item (1-based). This should be set to 1 for a tube.
> The Y-coordinate (row) of the sample holder within the labware item (1-based). This should be set to 1 for a tube.

Flipped the x/y in the JSON payload for substances, but kept it 'reversed' for the solvent payload

#### Duplicate rows from same experiment id

**Issue:**
When raw instrument files (e.g. `209103.csv`) are uploaded, they are stored in `file_info_v1` (this is considered IDS formatted data on TDP).
The platform then parses these files and populates several related tables:

```
client_preludetx_tecan_parser_v1_root ‚Üí experiment-level metadata (instrument, timestamps, user)
client_preludetx_tecan_parser_v1_plates ‚Üí parsed plate-level data
client_preludetx_tecan_parser_v1_cassettes ‚Üí cassette information used during the run
client_preludetx_tecan_parser_v1_fluids ‚Üí fluid details (concentrations, solvents, dispense volumes)
client_preludetx_tecan_parser_v1_tecan_file_data ‚Üí parsed TECAN file metadata linked to plates
client_preludetx_tecan_parser_v1_tecan_file_data_wells ‚Üí parsed well-level dispense and result data
```

Each table is connected by `uuid` and `parent_uuid`, creating a hierarchical structure:

```
root (uuid)
 ‚îú‚îÄ‚îÄ plates (parent_uuid)
 ‚îú‚îÄ‚îÄ cassettes (parent_uuid)
 ‚îú‚îÄ‚îÄ fluids (parent_uuid)
 ‚îú‚îÄ‚îÄ tecan_file_data (parent_uuid)
      ‚îî‚îÄ‚îÄ tecan_file_data_wells (parent_uuid)
```

Currently, it seems impossible to guarantee we can retrieve the parsed data for a specific file (like `209103.csv`) instead of an older or incorrect upload.
Example rows from the `client_preludetx_tecan_parser_v1_plates` table for experiment ID 209103:

| uuid | parent_uuid | pk | name | experiment_id | id | type | rows | columns | additional_volume_value | additional_volume_unit | dmso_limit_value | dmso_limit_unit | donnot_shake | donnot_dispense |
|---- | ----------- | -- | ---- | ------------- | -- | ---- | ---- | ------- | ----------------------- | ---------------------- | ---------------- | --------------- | ------------ | ---------------|
| e6fc00b2-cd34-46ae-b252-9568f41fd6e4 | 0427ce76-43d1-493b-820d-d1cf76229a36 | 1.0 | 209103_01 | 209103 | 01 | 384 well | 16 | 24 | 9.8 | uL | 0.01 | % |  |  |
| 65fa484f-4d80-4966-bb21-2b9d72299285 | 0427ce76-43d1-493b-820d-d1cf76229a36 | 2.0 | 209103_02 | 209103 | 02 | 384 well | 16 | 24 | 9.8 | uL | 0.01 | % |  |  |
| d0747745-25cd-4553-8a44-47f90bf5b15d | e59edcfd-5eae-4f9a-9d12-c10b8144347b | 1.0 | 209103_01 | 209103 | 01 | 384 well | 16 | 24 | 9.8 | uL | 0.01 | % |  |  |
| 695c6daa-9673-4830-b370-a6eda52f94a9 | e59edcfd-5eae-4f9a-9d12-c10b8144347b | 2.0 | 209103_02 | 209103 | 02 | 384 well | 16 | 24 | 9.8 | uL | 0.01 | % |  |  |

This shows two sets of data (each with two plates) sharing the same experiment_id (209103), but different `parent_uuid` values. These likely correspond to different raw data file uploads.

At the same time, the `file_info_v1` table contains multiple files for 209103 (for example, `209103 2022-10-25 1605.csv` and `209103_01.csv`) but there is no clear way to relate these files to the corresponding rows in the parsed tables like plates or root.

This ambiguity makes it impossible to precisely select or analyze data from a specific file upload without referencing the original file names, which are not linked in the parsed tables.


#### Issue with no rows extracted

**Issue:**
```
Returns ‚ùå Error: No rows returned from Athena.
```

Tried to run on terminal; `aws athena start-query-execution ${QUERY_STRING}` and returns 0 rows, however in Tetrascience UI, it returns the 616 rows

```bash
aws athena start-query-execution \
    --query-string "WITH ..." \
    --result-configuration OutputLocation=s3://ts-platform-prod-athena-results/preludetx/ \
    --work-group preludetx \
    --region us-east-1

# get query results
aws athena get-query-results --query-execution-id <ID>
 
# get query metadata 
aws athena get-query-execution --query-execution-id <ID>
```

**Resolution**
Need to create aws athena keys on UAT and query from UAT and not PROD; change workgroup and s3_output
