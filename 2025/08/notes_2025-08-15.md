[Home](../../main.md) | [Prev: Day 211](notes_2025-08-14.md) | [Next: Day 213](./notes_2025-08-18.md)

## üìù Day 212, Friday - `notes_2025-08-15.md`

### US341
- develop script to ingest tecan file and upload using mosaic api
    * the challenge is that raw file names can contain an experiment id, however the plate_ids inside the file content can be different, the schema design for IDS does not account for this and there is no logic to account for all data from a raw file with different plate ids.
    * 3 main options discussed on how to incorporate logic for handling different plate ids (barcodes) in raw csv files:
        1. create a `.txt` file with experiment ID as file name
            * simple, but user can easily make errors, additional steps, quite messy
        2. make an on-going schedule that pings DTX and MOSAIC for newly added barcodes (plate ids)
            * significant code to add; can introduce more error-prone steps, will bloat the logs due batch processing (each payload is already ~8k lines of json)
        3. parse the original raw file twice and get the plate ids (barcodes) 
            * makes the most sense without adding extra steps for users and additional significant code
    * **UPDATE**: out of the 3, Preludetx wanted option (1); so currently developing this functionality; this id due to the fact that the users want full control of what plate ids (barcodes) to upload since some tecan files can have mixed plate ids, they sometimes dont want to automatically upload them and have fine grain control
    * Define a naming format for file where file includes a list of plate barcodes to process, `Jcote_DATE_TIME.csv`
    * `Jcote_12-AUG-2025_13:38.txt`  with contents: 

```
205100_01
205100_02
205101_01
205102_01
```

* sql testing to find fluid names from barcodes:

```sql
WITH plate_files AS (
  SELECT DISTINCT 
    parent_uuid,
    name,
    regexp_extract(
      regexp_extract("$path", '[^/]+$'), 
      '([^__]+\.csv)(?=__|$)'
    ) AS file_name
  FROM client_preludetx_tecan_parser_v1_plates
),
plate_parent AS (
  SELECT 
    pf.parent_uuid,
    pf.name,
    pf.file_name,
    from_iso8601_timestamp(r.time_start) AS time_start,
    r.experiment_protocol
  FROM plate_files pf
  JOIN client_preludetx_tecan_parser_v1_root r
    ON pf.parent_uuid = r.uuid
  WHERE from_iso8601_timestamp(r.time_start) <= TIMESTAMP '2024-01-01 00:00:00 UTC'
  ORDER BY from_iso8601_timestamp(r.time_start) DESC
),
plate_uuids AS (
  SELECT uuid, parent_uuid, plate_fk
  FROM client_preludetx_tecan_parser_v1_tecan_file_data
  WHERE parent_uuid IN (SELECT parent_uuid FROM plate_parent)
),
fluids_for_parent AS (
  SELECT pk, name, stock_concentration_value, stock_concentration_unit, solvent,
         cassette_fk, dispense_head, volume_dispensed_value, volume_dispensed_unit,
         volume_loaded_value, volume_loaded_unit, parent_uuid
  FROM client_preludetx_tecan_parser_v1_fluids
  WHERE parent_uuid IN (SELECT parent_uuid FROM plate_parent)
)
SELECT 
  pp.parent_uuid,
  pp.name AS barcode,  
  f.name AS fluid_name,
  pp.file_name,
  date_format(pp.time_start AT TIME ZONE 'UTC', '%Y-%m-%d %H:%i:%s') AS time_start_formatted,
  pp.experiment_protocol
FROM plate_parent pp
LEFT JOIN fluids_for_parent f
  ON pp.parent_uuid = f.parent_uuid
ORDER BY pp.time_start DESC, pp.name ASC;
```

* barcodes to test the full linked pipeline
    * both of these plate ids (barcodes) have majority existing PRT#'s however a couple non-existing (good test)
        * tested on postman mosaic API to ensure the returning payload has filled substance arrays
    * generate `.txt` file and place in `/Screening/Tecan_Mosaic_UAT` for FLA ingestion
    * this will trigger Validate barcode pipeline, which then pipes to Post Tecan IDS to Mosaic pipeline; the output of Validate barcodes is a validated `.txt` file (`TMP` file category) to read the plate ids
    * name the file, `strinh_15-AUG-2025_13-30.txt` with contents

```text
241200_01
210587_01
```


### US355
- investigate tetrascience pipeline issue Envision and Licor RAW to IDS to Dotmatics
    * issue with pipeline erroring
    * I inspected the two json output files and nothing looks off¬†hard to tell with the limited logs¬†this error points to well A21 if i'm not mistaken: `well at row 1, column 21 on plate 275823_01`¬†and the json shows, nothing looks off


```json
    { ¬†¬†¬†¬† 
        "reference":¬†"A21", ¬†¬†¬†¬† 
        "result":¬†1691.0 ¬†¬† 
    },

    {
        "reference": "B21",
        "result": 10640.0
    },

```

- from `dotmatics_addPlates_body.json[rawData]`
```json
45:{4 items
"row":1
"col":21
"value":713
"status":0
}
```

- from `275822_01.json`

```json
45:{2 items
"reference":"B22"
"result":713
}
```
